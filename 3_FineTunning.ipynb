{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7390d5-46f5-4631-bafe-5113d0e7d2cc",
   "metadata": {},
   "source": [
    "## Model Initialization and Summary Generation\n",
    "\n",
    "In this section of the project, we utilize the BART (Bidirectional and Auto-Regressive Transformers) model developed by Facebook AI. BART is specifically designed for tasks that involve both understanding and generating natural language, making it well-suited for applications like summarization. This model integrates the benefits of both bidirectional models (e.g., BERT) for understanding context and auto-regressive models (e.g., GPT) for generating text, which allows it to effectively model the dependencies and nuances in languagting accurate and coherent summaries of Albanian parliamentary speeches, aligning with the project's goal to enhance accessibility and understanding of political discourse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93015f6-311b-4c57-9d72-2e4bc999cca7",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "The notebook begins by loading the necessary datasets:\n",
    "- `Sampled_Alb_Speeches.xlsx` contains a subset of speeches that need summarization.\n",
    "- `Summarized_Albanian_Speeches.xlsx` contains pre-generated summaries for a comparative study.\n",
    "\n",
    "These datasets are merged based on the 'id' column to align each speech with its corresponding summary, facilitating a direct comparison and training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7df8954-a7e7-4eea-9f1c-494739c66126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "unlabeled_data_alb = pd.read_excel('Sampled_Alb_Speeches.xlsx')\n",
    "sum_eng = pd.read_excel('Summarized_Albanian_Speeches.xlsx')\n",
    "\n",
    "# Merge the datasets on the 'id' column\n",
    "merged_data = pd.merge(unlabeled_data_alb[['id', 'text']], sum_eng[['id', 'summarization']], on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199c19b0-037a-488e-909f-0c000dcd93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('labeled_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f319d61-af63-4cd0-8c2c-d58143af3150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-11_22</td>\n",
       "      <td>A jeni dakord ju shefat e grupeve parlamentare...</td>\n",
       "      <td>Me 72 vota “pro”, 3 “kundër”, 2 “abstenime”, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-07_34</td>\n",
       "      <td>Unë e di që ka deputetë opozitarë, ka deputetë...</td>\n",
       "      <td>Kryeministri Thaçi i tha “po” Daqidit, atje. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-19_188</td>\n",
       "      <td>Faleminderit, kryetar! Komisioni për të Drejta...</td>\n",
       "      <td>Komisioni për të drejtat e njeriut, barazi gji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-11-06_240</td>\n",
       "      <td>I nderuar deputet, unë të kuptoj se kemi nganj...</td>\n",
       "      <td>Të pranishëm janë 67 deputetë. 53 votuan “pro”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-11-20_173</td>\n",
       "      <td>Ju faleminderit! Mendoj se deri më tani Kuvend...</td>\n",
       "      <td>Kuvendi me 63 vota “pro”, asnjë kundër, 1 abst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "0   2011-11-11_22  A jeni dakord ju shefat e grupeve parlamentare...   \n",
       "1   2014-05-07_34  Unë e di që ka deputetë opozitarë, ka deputetë...   \n",
       "2  2021-10-19_188  Faleminderit, kryetar! Komisioni për të Drejta...   \n",
       "3  2008-11-06_240  I nderuar deputet, unë të kuptoj se kemi nganj...   \n",
       "4  2008-11-20_173  Ju faleminderit! Mendoj se deri më tani Kuvend...   \n",
       "\n",
       "                                       summarization  \n",
       "0  Me 72 vota “pro”, 3 “kundër”, 2 “abstenime”, K...  \n",
       "1  Kryeministri Thaçi i tha “po” Daqidit, atje. P...  \n",
       "2  Komisioni për të drejtat e njeriut, barazi gji...  \n",
       "3  Të pranishëm janë 67 deputetë. 53 votuan “pro”...  \n",
       "4  Kuvendi me 63 vota “pro”, asnjë kundër, 1 abst...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885628b5-eaba-4262-9f00-04d84a35ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27256269-dabb-4f31-9000-ce90f8d2bf1b",
   "metadata": {},
   "source": [
    "## Model Setup and Summary Generation\n",
    "\n",
    "For the summarization task, we utilize the `BART` model, renowned for its efficacy in sequence-to-sequence tasks:\n",
    "- **Model and Tokenizer Initialization:** The BART model and its tokenizer are initialized. The tokenizer prepares the text data for processing by the model, handling tasks such as splitting text into tokens, generating tokens suitable for model input, and setting the maximum length for sequence truncation.\n",
    "- **Summary Generation Function:** We define a custom function `generate_summary_test` to encapsulate the entire summarization process. This function manages text input, invoking the model to generate summaries, and then decoding the output to human-readable text.\n",
    "## Training \n",
    "\n",
    "The processed dataset is split into training and testing subsets, providing a foundation for both training the model and evaluating its performance. We detail the setup for model training using Hugging Face’s `transformers` and `datasets` libraries, which include:\n",
    "- **Tokenization:** Text data is converted into a format suitable for the model, ensuring that input lengths are managed and that the data fits model requirements.\n",
    "- **Training Arguments Setup:** Parameters for training the BART model are specified, including learning rate, batch size, and the number of epochs.\n",
    "- **Training Execution:** Utilizing `Seq2SeqTrainer`, the model undergoes training where it learns to generate summaries that are both concise and relevant to the input speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97cdd40b-c0f7-4106-bd61-264f415d3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into 80% train and 20% validation\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60bd01d4-a3a6-42ac-915f-2e9c08e1f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'summarization'],\n",
       "        num_rows: 440\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'summarization'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68690fc0-e4dd-44ed-b470-87850b10dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns if necessary\n",
    "dataset = dataset.rename_column(\"summarization\", \"summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23fadd5-f9b8-4da1-9619-cea64f757244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce6fb4fc-8acf-4985-954e-5056d64c9cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b5291fd82143fa8229b5fa29584f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e31bcebdaf4a7bb21e5aad2b74de0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_checkpoint = \"facebook/bart-large-cnn\"  # Example using BART model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples['text'], max_length=1024,truncation=True, padding=\"max_length\")\n",
    "    # Prepare labels for summarization\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['summary'], max_length=500, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e35c3e7-969e-4f84-be75-8f2fc9fec96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 440\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10132d48-1b36-45c9-a34b-93477d8ab957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\binawork\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:597: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 52:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.630013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.627302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=330, training_loss=0.6130429816968513, metrics={'train_runtime': 3140.0419, 'train_samples_per_second': 0.42, 'train_steps_per_second': 0.105, 'total_flos': 2860578074787840.0, 'train_loss': 0.6130429816968513, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "# Ensure your training arguments are correctly set\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    ")\n",
    "\n",
    "# Data collator that dynamically pads the batches\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Initialize the Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Now you can train your model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0a7cd49-cccc-42e9-802f-3f90187c7279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./results\\\\tokenizer_config.json',\n",
       " './results\\\\special_tokens_map.json',\n",
       " './results\\\\vocab.json',\n",
       " './results\\\\merges.txt',\n",
       " './results\\\\added_tokens.json',\n",
       " './results\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./results')\n",
    "tokenizer.save_pretrained('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9f6d95-7999-448d-b2b7-02138b2609cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuvendi miratoi rekomandimet e propozuara nga Grupi Parlamentar i Lidhjes Demokratike lidhur me Raportin e Progresit për Kosovën, të vitit 2011. Me 72 vota “pro”, 3 “kundër” ’, 2 “abstenime” me shumicë të votave, pika e fundit e rendit të ditës hiqet nga shqyrtimi. Deputetët në një mbledhje mund të parashtrojnë më së shumti dy pyetje parlamentare.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./results\")\n",
    "summarizer = pipeline(\"summarization\", model=\"./results\", tokenizer=tokenizer)\n",
    "\n",
    "# Example text\n",
    "text_to_summarize = \"A jeni dakord ju shefat e grupeve parlamentare për këtë? Dakord! Atëherë, shkojmë me procedurën e votimit. Regjia, le të përgatitet t’i votojmë rekomandimet e propozuara nga Grupi Parlamentar i Lidhjes Demokratike lidhur me Raportin e Progresit për Kosovën, për vitin 2011. Votojmë tash. Me 72 vota “për’, 3 “kundër” ’, 2 “abstenime”, Kuvendi miratoi rekomandimet e propozuara nga Grupi Parlamentar i Lidhjes Demokratike. Para se të vazhdojmë me rendin e ditës, në konsultë me kryetarët e grupeve parlamentare, pika 13 e rendit të ditës, për faktin se lënda është në Gjykatën Kushtetuese, që Kuvendi mos të bëjë interferim në këtë lëndë, shtyhet ose hiqet nga rendi i ditës për seancën e sotme. Komisioni, a e do fjalën? Jo. Atëherë, kërkohet një deklarim i seancës. Kush është për këtë propozim, me ngritje dore? Faleminderit! A ka kundër? A ka abstenim? Faleminderit! Me shumicë të votave, pika e fundit e rendit të ditës hiqet nga shqyrtimi. Në radhë kemi pikën dytë të rendit të ditës: 2. Koha për pyetjet parlamentare Në pajtim me nenin 45, pika 1 të Rregullores së Kuvendit, koha për pyetjet e deputetëve për Qeverinë është e kufizuar në 60 minuta. Deputetët në një mbledhje mund t’i parashtrojnë më së shumti dy pyetje parlamentare. Deputeti Shaip Muja nuk është këtu. Deputetja Aurora Bakalli, pyetje për ministrin Ferid Agani. Deputete, e ke fjalën!\"\n",
    "\n",
    "# Generate summary\n",
    "summary = summarizer(text_to_summarize, max_length=500, min_length=50, do_sample=False)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0700a735-5d07-47e8-9346-a730ceaf36f7",
   "metadata": {},
   "source": [
    "## Summarization Evaluation\n",
    "\n",
    "To assess the quality of the generated summaries, we use the ROUGE metric, which helps in measuring the overlap of n-grams between the generated summaries and the ground truths. Additionally, cosine similarity scores provide a measure of semantic similarity between the generated and reference summaries, offering insight into the model's effectiveness in capturing the core meaning and important points of the speeches.\n",
    "\n",
    "This notebook not only aids in understanding the practical steps involved in fine-tuning a summarization model but also provides a framework for evaluating its real-world applicability to legislative proceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62deed33-bb6a-46c2-a95d-c1a105ebab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in e:\\binawork\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8e6a66a-dc48-4ac1-b511-f428f6010c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "data_truth = pd.read_excel('labeled_data.xlsx')\n",
    "\n",
    "# Assume the data has columns 'Speech' and 'GroundTruthSummary'\n",
    "# Select 50 random samples\n",
    "sampled_data_truth = data_truth.sample(n=50, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe65529b-756f-47bb-9e9a-01c534919e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe7a4fcf-3b48-42d7-b74f-3786b57cb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 500, but your input_length is only 491. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=245)\n",
      "Your max_length is set to 500, but your input_length is only 471. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=235)\n",
      "Your max_length is set to 500, but your input_length is only 483. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=241)\n",
      "Your max_length is set to 500, but your input_length is only 433. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=216)\n",
      "Your max_length is set to 500, but your input_length is only 489. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=244)\n",
      "Your max_length is set to 500, but your input_length is only 428. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=214)\n",
      "Your max_length is set to 500, but your input_length is only 473. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=236)\n",
      "Your max_length is set to 500, but your input_length is only 491. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=245)\n",
      "Your max_length is set to 500, but your input_length is only 486. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=243)\n",
      "Your max_length is set to 500, but your input_length is only 485. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=242)\n",
      "Your max_length is set to 500, but your input_length is only 259. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=129)\n"
     ]
    }
   ],
   "source": [
    "# Generate summaries\n",
    "sampled_data_truth['GeneratedSummary'] = sampled_data_truth['text'].apply(\n",
    "    lambda x: summarizer(x, max_length=500, min_length=50, do_sample=False)[0]['summary_text']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "029dcdc9-a23d-445a-9eef-5d1d9fbda658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>summarization</th>\n",
       "      <th>GeneratedSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2020-10-16_221</td>\n",
       "      <td>Faleminderit! Të nderuar qytetarë, Të nderuar ...</td>\n",
       "      <td>Kosova ka një projektligj që do të kërkonte që...</td>\n",
       "      <td>Deputeti i Kosovës: Ky projektligj ka ardhur e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2021-11-18_849</td>\n",
       "      <td>Administrata, më informoni sa janë të pranishë...</td>\n",
       "      <td>Deputetët nuk po i përmbahen asaj që kërkohet ...</td>\n",
       "      <td>76 deputetë i kemi të pranishëm, do të votojmë...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2009-05-14_119</td>\n",
       "      <td>Për informatën, për pozicionin e njeriut përgj...</td>\n",
       "      <td>Deputeti i Kosovës: “Besoj se po krijohet një ...</td>\n",
       "      <td>“Shumë hapa që po ndodhin në këtë Kuvend, bëjn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2024-02-29_167</td>\n",
       "      <td>Faleminderit, kryetar!  Faleminderit deputet B...</td>\n",
       "      <td>MRI ka qenë një listë pritjeje 1 deri në 2 vje...</td>\n",
       "      <td>“Besoj edhe për qytetarët e Gjakovës instalimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2011-11-17_139</td>\n",
       "      <td>Faleminderit, kryetar! Kjo Qeveri edhe në këtë...</td>\n",
       "      <td>Qeveria e Kosovës na e ka bërë të qartë se nuk...</td>\n",
       "      <td>Kryeministri: Kjo Qeveri e ka bërë të qartë se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2018-04-27_133</td>\n",
       "      <td>Faleminderit, zoti kryetar! Edhe unë pajtohem ...</td>\n",
       "      <td>Jam dakord që shumë deputetë kanë shkuar në pë...</td>\n",
       "      <td>“Nuk dua absolutisht të pajtohem me deputetët ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2021-12-13_56</td>\n",
       "      <td>Faleminderit, i nderuari kryetar i Kuvendit! I...</td>\n",
       "      <td>Ministria e Kulturës, Rinisë dhe Sportit ka bë...</td>\n",
       "      <td>Ministria e Kulturës, Rinisë dhe Sportit ka bë...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2013-06-20_66</td>\n",
       "      <td>Faleminderit, kryetar! Përshëndetje për minist...</td>\n",
       "      <td>Koalicioni për Kosovën e Re mbështet rekomandi...</td>\n",
       "      <td>Koalicioni për Kosovën e Re e mbështet rekoman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2023-02-23_139</td>\n",
       "      <td>Meqenëse, pyetja e deputetit është për pikën e...</td>\n",
       "      <td>Deputetët votuan pro, asnjë kundër dhe asnjë a...</td>\n",
       "      <td>Kuvendi ratifikoi marrëveshjen për njohjen e k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2006-04-06_19</td>\n",
       "      <td>Ju faleminderit. Votojmë për këtë pikë të rend...</td>\n",
       "      <td>Shqyrtimi i dytë i projektligjit për inspektor...</td>\n",
       "      <td>Shqyrtimi i dytë i Projektligjit për inspektor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               text  \\\n",
       "195  2020-10-16_221  Faleminderit! Të nderuar qytetarë, Të nderuar ...   \n",
       "79   2021-11-18_849  Administrata, më informoni sa janë të pranishë...   \n",
       "480  2009-05-14_119  Për informatën, për pozicionin e njeriut përgj...   \n",
       "109  2024-02-29_167  Faleminderit, kryetar!  Faleminderit deputet B...   \n",
       "522  2011-11-17_139  Faleminderit, kryetar! Kjo Qeveri edhe në këtë...   \n",
       "532  2018-04-27_133  Faleminderit, zoti kryetar! Edhe unë pajtohem ...   \n",
       "84    2021-12-13_56  Faleminderit, i nderuari kryetar i Kuvendit! I...   \n",
       "368   2013-06-20_66  Faleminderit, kryetar! Përshëndetje për minist...   \n",
       "132  2023-02-23_139  Meqenëse, pyetja e deputetit është për pikën e...   \n",
       "364   2006-04-06_19  Ju faleminderit. Votojmë për këtë pikë të rend...   \n",
       "\n",
       "                                         summarization  \\\n",
       "195  Kosova ka një projektligj që do të kërkonte që...   \n",
       "79   Deputetët nuk po i përmbahen asaj që kërkohet ...   \n",
       "480  Deputeti i Kosovës: “Besoj se po krijohet një ...   \n",
       "109  MRI ka qenë një listë pritjeje 1 deri në 2 vje...   \n",
       "522  Qeveria e Kosovës na e ka bërë të qartë se nuk...   \n",
       "532  Jam dakord që shumë deputetë kanë shkuar në pë...   \n",
       "84   Ministria e Kulturës, Rinisë dhe Sportit ka bë...   \n",
       "368  Koalicioni për Kosovën e Re mbështet rekomandi...   \n",
       "132  Deputetët votuan pro, asnjë kundër dhe asnjë a...   \n",
       "364  Shqyrtimi i dytë i projektligjit për inspektor...   \n",
       "\n",
       "                                      GeneratedSummary  \n",
       "195  Deputeti i Kosovës: Ky projektligj ka ardhur e...  \n",
       "79   76 deputetë i kemi të pranishëm, do të votojmë...  \n",
       "480  “Shumë hapa që po ndodhin në këtë Kuvend, bëjn...  \n",
       "109  “Besoj edhe për qytetarët e Gjakovës instalimi...  \n",
       "522  Kryeministri: Kjo Qeveri e ka bërë të qartë se...  \n",
       "532  “Nuk dua absolutisht të pajtohem me deputetët ...  \n",
       "84   Ministria e Kulturës, Rinisë dhe Sportit ka bë...  \n",
       "368  Koalicioni për Kosovën e Re e mbështet rekoman...  \n",
       "132  Kuvendi ratifikoi marrëveshjen për njohjen e k...  \n",
       "364  Shqyrtimi i dytë i Projektligjit për inspektor...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4a8edab-6a75-4754-800c-4f33db9cb605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores: {'rouge-1': {'r': 0.49484378224486014, 'p': 0.4627724775496203, 'f': 0.47319500685953125}, 'rouge-2': {'r': 0.26604558518588844, 'p': 0.26183449173648266, 'f': 0.26002665494944616}, 'rouge-l': {'r': 0.4622348700844644, 'p': 0.4333370530793607, 'f': 0.442537774292043}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(\n",
    "    sampled_data_truth['GeneratedSummary'].tolist(), \n",
    "    sampled_data_truth['summarization'].tolist(), \n",
    "    avg=True\n",
    ")\n",
    "\n",
    "print(\"ROUGE scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6ff2097-0f8f-4e35-b333-b4c8e1b4a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries = sampled_data_truth['GeneratedSummary'].tolist()\n",
    "reference_summaries = sampled_data_truth['summarization'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b72bba3-ec58-4cf1-b9cc-ac2a90a82a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Concatenate both lists for vectorization\n",
    "all_summaries = generated_summaries + reference_summaries\n",
    "\n",
    "# Vectorize the summaries\n",
    "tfidf_matrix = vectorizer.fit_transform(all_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e0439f1-9508-467e-bfa0-e9aedf079549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Scores: [0.43118996 0.29003732 0.45690902 0.30608323 0.51787621 0.49353997\n",
      " 0.76014178 0.71481353 0.32968777 0.67598782 0.64319924 0.47972934\n",
      " 0.35331836 0.57893594 0.33159021 0.45276003 0.63578242 0.39375678\n",
      " 0.51048602 0.50148325 0.33725724 0.16648575 0.48276992 0.65399287\n",
      " 0.34562904 0.38985048 0.50105118 0.55696018 0.50757495 0.55234078\n",
      " 0.72352205 0.42689647 0.44009377 0.33873136 0.26108976 0.48449624\n",
      " 0.63829434 0.43500718 0.72184326 0.56975248 0.23311903 0.68047117\n",
      " 0.39291119 0.56394442 0.52926342 0.38040513 0.43174378 0.42675032\n",
      " 0.31614873 0.30777409]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity\n",
    "# Assuming the first half are generated and the second half are references\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix[:len(generated_summaries)], tfidf_matrix[len(generated_summaries):])\n",
    "\n",
    "# Diagonal elements give the similarity scores between corresponding summaries\n",
    "cosine_scores = similarity_matrix.diagonal()\n",
    "\n",
    "print(\"Cosine Similarity Scores:\", cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcd42fd9-54ee-4c2a-a805-caba369b1a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47306957578878167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(cosine_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9dea15-718d-4642-8a7f-6dfe2037acd9",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The fine-tuned model has demonstrated promising results in summarizing Albanian parliamentary speeches. The evaluation of the model's performance yielded the following scores:\n",
    "\n",
    "- **Average Cosine Similarity:** 0.4731\n",
    "- **ROUGE Scores:**\n",
    "  - **ROUGE-1:** 0.4769 (measures the overlap of unigrams between the generated and reference summaries)\n",
    "  - **ROUGE-2:** 0.2626 (measures the overlap of bigrams)\n",
    "  - **ROUGE-L:** 0.4460 (measures the longest common subsequence, which is useful for evaluating sentence-level structure similarity)\n",
    "\n",
    "These metrics indicate that the model is reasonably effective in capturing the gist and essential details of the speeches, reflecting both lexical and semantic understanding. However, there is still room for improvement, especially in capturing more detailed relationships and nuances expressed in the speeches, as suggested by the lower ROUGE-2 score. Future work could explore more advanced techniques for fine-tuning or employing additional pre-processing steps to further enhance the model's summarization capabilities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
