{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7ce018-ce10-48e5-b4a6-3eff9915d934",
   "metadata": {},
   "source": [
    "# Evaluating Fine-Tuning vs. Prompting Techniques for Summarizing Albanian Parliamentary Speeches\n",
    "In this notebook, we explore the efficacy of various Natural Language Processing (NLP) techniques for summarizing Albanian parliamentary speeches. The primary focus is on a comparative analysis between fine-tuning a Language Model (LM) and employing several prompt engineering strategies—specifically zero-shot, one-shot, and multi-shot approaches. The goal is to determine if prompt engineering, particularly multi-shot prompting, can provide a competitive alternative to the resource-intensive process of fine-tuning. After establishing the most effective prompting strategy, we further compare it to a fine-tuned model to ascertain which method yields superior summarization results for our specific dataset.\n",
    "ine-tuning method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc34e4-001a-46db-aab5-295e985471a9",
   "metadata": {},
   "source": [
    "## Zero-shot Prompt Engineering\n",
    "Zero-shot prompting involves providing the model with no prior examples or context other than the task description itself. This approach tests the model's ability to generalize from its pre-trained knowledge without any task-specific tuning.\n",
    "\n",
    "<img src=\"images/zero-shot.jpg\" alt=\"Zero-shot Prompting Example\" width=\"70%\"/>\n",
    "\n",
    "## One-shot Prompt Engineering\n",
    "One-shot prompting provides the model with a single example of the task at hand before asking it to perform the task on new data. This method helps the model adjust its responses based on the context provided by one example.\n",
    "\n",
    "<img src=\"images/one-shot.jpg\" alt=\"One-shot Prompting Example\" width=\"70%\"/>\n",
    "\n",
    "## Multi-shot Prompt Engineering\n",
    "Multi-shot prompting provides the model with multiple examples of the task, offering more context and variations. This approach can potentially lead to better understanding and performance by showcasing different ways the task can be approached.\n",
    "\n",
    "<img src=\"images/multi-shot.jpg\" alt=\"Multi-shot Prompting Example\" width=\"70%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ac49cd-f732-402d-966d-eaed5736e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "api_key = os.getenv('OPENAI_API_KEY', 'sk-key-here')  # Replace with your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Load the sentence embedding model for similarity calculation\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4601ae-379c-47a9-825e-5dde5f9de7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a summary using OpenAI's GPT model with different shot settings\n",
    "def generate_summary(text, example_texts=None, example_summaries=None, shot_type=\"zero-shot\"):\n",
    "    if shot_type == \"zero-shot\":\n",
    "        prompt = f\"Summarize the following Albanian parliamentary speech in Albanian: {text}\"\n",
    "    elif shot_type == \"one-shot\" and example_texts and example_summaries:\n",
    "        prompt = f\"Given this Albanian parliamentary speech text: '{example_texts[0]}' a good summary for it is this: '{example_summaries[0]}'. Now summarize the following Albanian parliamentary speech in Albanian: {text}\"\n",
    "    elif shot_type == \"multi-shot\" and example_texts and example_summaries:\n",
    "        examples_prompt = \" \".join([f\"Given this Albanian parliamentary speech text: '{example_texts[i]}' a good summary for it is this: '{example_summaries[i]}'.\" for i in range(len(example_texts))])\n",
    "        prompt = f\"{examples_prompt} Now summarize the following Albanian parliamentary speech in Albanian: {text}\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid shot type or insufficient examples provided for multi-shot or one-shot summarization.\")\n",
    "\n",
    "    try:\n",
    "        completion = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        return completion.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during summary generation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38a9838a-7523-40e6-b220-766fd7c8937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity and ROUGE scores between two texts\n",
    "rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "def calculate_scores(reference, summary):\n",
    "    cosine_score = util.pytorch_cos_sim(\n",
    "        embedding_model.encode(reference, convert_to_tensor=True),\n",
    "        embedding_model.encode(summary, convert_to_tensor=True)\n",
    "    ).item()\n",
    "    rouge_scores = rouge.score(reference, summary)\n",
    "    return cosine_score, rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8b658f-a133-4295-87be-27af611d556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of examples you want to provide:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter example text 1:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Faleminderit, kryetar! Pyetja është deponuar dy muaj më parë dhe përfshin tre ministra, në fakt është një për ministrin Lekaj, një për ministren Reshitaj dhe një për ministrin Gashi lidhur me vizitën e tyre në Gjakovë më 7 shkurt 2018. Ministër, gjatë kësaj vizite ju para medieve keni deklaruar, mes tjerash, se do t’i ndihmoni Komunës së Gjakovës në projektin e stërzgjatur të impiantit të ujërave të zeza, projekt ky me një vlerë prej 16 milionë euro. Pyetja është: Buxheti i miratuar i Kosovës për vitin 2018 në ministrinë tuaj përmban investime nga ministria për impiantin e ujërave të zeza në Prishtinë, 2 milionë e 700 mijë euro investim; impiantin e ujërave të zeza në Pejë, 3 milionë e 800 mijë euro investim, por nuk ka asnjë vijë buxhetore për projektin e impiantit të ujërave të zeza në Gjakovë. Nga cila kategori, ministre, do t’i ndihmoni ndërtimit të impiantit të ujërave të zeza të Gjakovës dhe nëse do t’i ndihmoni, me çfarë vlere është ajo ndihmë?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the summary for example text 1:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Pyetja është ngritur dy muaj më parë dhe përfshin tre ministra. Pyetja është: Buxheti i miratuar i Kosovës për vitin 2018 në ministrinë tuaj përmban investime nga ministria për impiantin e ujërave të zeza në Prishtinë, 2 milionë e 700 mijë euro investim. Por nuk ka asnjë linjë buxhetore për projektin e impiantit të ujërave të zeza në Gjakovë. Nga cila kategori, ministër, do ta ndihmoni ndërtimin e kanalizimeve të ujërave të zeza në Gjakovë dhe nëse do t'i ndihmoni, çfarë vlere ka kjo ndihmë?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter example text 2:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Faleminderit kryetar! Po mendoj se ne anëtarët e Komisionit duhet të jemi më të përgjegjshëm nga vetë fakti se kemi marrë pjesë në intervistë dhe i kemi intervistuar 57 kandidatë. Procedura se si duhet të votohet, do të thotë ka qenë një procedurë e pavarur nga secili anëtar i Komisionit por nga vetë fakti se ky proces është përmbyllur me nënshkrimin e të gjithë anëtarëve të Komisionit lë të kuptohet se ne duhet të vazhdojmë sot apo duhet të fillojmë me përmbylljen e këtij procesi dhe mbetet në çështjen e deputetëve se si të votojnë për kandidatët. Unë mendoj se ka kandidatë këtu që janë kredibilë, ka kandidatë që e kanë dëshmuar veten atë ditë në intervistë, kandidatë që kanë edhe përvojë dhe mbetet që deputetët e Parlamentit të Kosovës të vlerësojnë secilin kandidat që të jetë anëtar i Bordit duke marrë për bazë, sikur që e tha edhe kolegia deputete se i kemi do afate që ne në shtator duhet t’i zëmë këto afate dhe njëkohësisht RTK-ja duhet t’i ketë anëtarët e Bordit. Mendoj se kjo mbetet në çështjen e deputetëve dhe unë kërkoj që votimi të bëhet pas pauze, nëse ka mundësi, se siç po shihet nuk ka as deputetë të mjaftueshëm, por kjo le të vlerësohet nga ana e udhëheqjes së Kuvendit. Faleminderit!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the summary for example text 2:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Mendoj se ne anëtarët e Komisionit duhet të jemi më të përgjegjshëm për vetë faktin që morëm pjesë në intervistë dhe intervistuam 57 kandidatë. Mendoj se kjo mbetet në çështjen e deputetëve dhe kërkoj që votimi të bëhet pas një pushimi, nëse është e mundur, sepse siç shihet nuk ka as deputetë të mjaftueshëm, por këtë le ta vlerësojë kryesia e Kuvendit. Faleminderit!“Kemi dy afate që duhet t'i përmbushim këto afate në shtator dhe në të njëjtën kohë RTK duhet të ketë anëtarët e Bordit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summaries with different approaches...\n"
     ]
    }
   ],
   "source": [
    "# Interaction for multi-shot prompting\n",
    "def get_multiple_examples():\n",
    "    num_examples = int(input(\"Enter the number of examples you want to provide: \"))\n",
    "    example_texts = []\n",
    "    example_summaries = []\n",
    "    for i in range(num_examples):\n",
    "        print(f\"Enter example text {i+1}:\")\n",
    "        example_text = input()\n",
    "        print(f\"Enter the summary for example text {i+1}:\")\n",
    "        example_summary = input()\n",
    "        example_texts.append(example_text)\n",
    "        example_summaries.append(example_summary)\n",
    "    return example_texts, example_summaries\n",
    "    \n",
    "    # Example for multi-shot\n",
    "example_texts, example_summaries = get_multiple_examples()\n",
    "\n",
    "# Generate summaries\n",
    "print(\"\\nGenerating summaries with different approaches...\")\n",
    "zero_shot_summary = generate_summary(example_texts[0], shot_type=\"zero-shot\")\n",
    "one_shot_summary = generate_summary(example_texts[0], [example_texts[0]], [example_summaries[0]], shot_type=\"one-shot\")\n",
    "multi_shot_summary = generate_summary(example_texts[0], example_texts, example_summaries, shot_type=\"multi-shot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e359f32-ea78-4062-8c30-91756124bd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating scores...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating scores...\")\n",
    "zero_cosine, zero_rouge = calculate_scores(example_summaries[0], zero_shot_summary)\n",
    "one_cosine, one_rouge = calculate_scores(example_summaries[0], one_shot_summary)\n",
    "multi_cosine, multi_rouge = calculate_scores(example_summaries[0], multi_shot_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f816fd-33ad-4042-9017-3dd33db2d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Metrics\n",
      "Zero-shot Summary: Kryetar, faleminderit! Pyetja është paraqitur dy muaj më parë dhe ka të bëjë me tre ministra, konkretisht për ministrin Lekaj, ministrin Reshitaj dhe ministrin Gashi, në lidhje me vizitën e tyre në Gjakovë më 7 shkurt 2018. Ministër, gjatë kësaj vizite, ju keni deklaruar para medieve se do të ndihmonit Komunën e Gjakovës në projektin e planifikuar të impiantit të ujërave të zeza, me një vlerë prej 16 milionë euro. Pyetja është: Buxheti i miratuar i Kosovës për vitin 2018 për ministrinë tuaj përfshin investime për impiantin e ujërave të zeza në Prishtinë, me një investim prej 2 milionë e 700 mijë euro; impiantin e ujërave të zeza në Pejë, me një investim prej 3 milionë e 800 mijë euro, por nuk ka asnjë linjë buxhetore për projektin e impiantit të ujërave të zeza në Gjakovë. Nga cila kategori, ministre, do të ndihmoni në ndërtimin e impiantit të ujërave të zeza në Gjakovë dhe nëse do të ndihmoni, me çfarë vlerë do të jetë ajo ndihmë?\n",
      "Cosine Similarity: 0.7273757457733154\n",
      "ROUGE Scores: {'rouge1': Score(precision=0.478494623655914, recall=0.9081632653061225, fmeasure=0.6267605633802817), 'rouge2': Score(precision=0.3675675675675676, recall=0.7010309278350515, fmeasure=0.4822695035460993), 'rougeL': Score(precision=0.44623655913978494, recall=0.8469387755102041, fmeasure=0.5845070422535212)}\n",
      "One-shot Summary: 'Pyetja është ngritur dy muaj më parë dhe përfshin tre ministra. Ministri gjatë vizitës në Gjakovë më 7 shkurt 2018 ka deklaruar se do të ndihmojë Komunën e Gjakovës në projektin e impiantit të ujërave të zeza me vlerë 16 milionë euro. Pyetja është: Buxheti i miratuar i Kosovës për vitin 2018 përmban investime për impiantin e ujërave të zeza në Prishtinë, 2 milionë e 700 mijë euro investim dhe në Pejë, 3 milionë e 800 mijë euro investim, por nuk ka asnjë linjë buxhetore për projektin e impiantit të ujërave të zeza në Gjakovë. Nga cila kategori, ministri, do të ndihmojë në ndërtimin e impiantit të ujërave të zeza në Gjakovë dhe nëse do ta ndihmojë, me çfarë vlerë është ajo ndihmë?'\n",
      "Cosine Similarity: 0.8833944797515869\n",
      "ROUGE Scores: {'rouge1': Score(precision=0.6231884057971014, recall=0.8775510204081632, fmeasure=0.7288135593220338), 'rouge2': Score(precision=0.5474452554744526, recall=0.7731958762886598, fmeasure=0.641025641025641), 'rougeL': Score(precision=0.5942028985507246, recall=0.8367346938775511, fmeasure=0.6949152542372882)}\n",
      "Few-shot Summary: Kryetar, pyetja është ngritur dy muaj më parë dhe përfshin tre ministra, në fakt një për ministrin Lekaj, një për ministren Reshitaj dhe një për ministrin Gashi në lidhje me vizitën e tyre në Gjakovë më 7 shkurt 2018. Gjatë kësaj vizite, ju, si ministër, keni deklaruar para medieve se do të ndihmonit Komunën e Gjakovës në projektin e stërzgjatur të impiantit të ujërave të zeza, me një vlerë prej 16 milionë euro. Pyetja është: Buxheti i miratuar i Kosovës për vitin 2018 në ministrinë tuaj përmban investime nga ministria për impiantin e ujërave të zeza në Prishtinë, 2 milionë e 700 mijë euro investim; impiantin e ujërave të zeza në Pejë, 3 milionë e 800 mijë euro investim, por nuk ka asnjë linjë buxhetore për projektin e impiantit të ujërave të zeza në Gjakovë. Nga cila kategori, ministre, do të ndihmoni ndërtimin e impiantit të ujërave të zeza të Gjakovës dhe nëse do ta ndihmoni, çfarë vlere ka kjo ndihmë?\n",
      "Cosine Similarity: 0.7558048963546753\n",
      "ROUGE Scores: {'rouge1': Score(precision=0.5217391304347826, recall=0.9795918367346939, fmeasure=0.6808510638297872), 'rouge2': Score(precision=0.48633879781420764, recall=0.9175257731958762, fmeasure=0.6357142857142857), 'rougeL': Score(precision=0.4945652173913043, recall=0.9285714285714286, fmeasure=0.6453900709219857)}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\nSimilarity Metrics\")\n",
    "print(\"Zero-shot Summary:\", zero_shot_summary)\n",
    "print(\"Cosine Similarity:\", zero_cosine)\n",
    "print(\"ROUGE Scores:\", zero_rouge)\n",
    "print(\"One-shot Summary:\", one_shot_summary)\n",
    "print(\"Cosine Similarity:\", one_cosine)\n",
    "print(\"ROUGE Scores:\", one_rouge)\n",
    "print(\"Few-shot Summary:\", multi_shot_summary)\n",
    "print(\"Cosine Similarity:\", multi_cosine)\n",
    "print(\"ROUGE Scores:\", multi_rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676efa06-b5b7-4a74-ac90-aa710709bcae",
   "metadata": {},
   "source": [
    "### Finding the best Hyperparameters for Multishot prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52e653e9-1cee-48ef-960d-e6fa22a2cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('labeled_data.xlsx').sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff065da1-c81a-491e-af2f-580513fda0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\binawork\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1 examples with temperature 0.3: Average Cosine Similarity = 0.8226228654384613, Average ROUGE Scores = {'rouge1': 0.48343722865411226, 'rouge2': 0.2538380629708836, 'rougeL': 0.3386794047338434}\n",
      "Tested 1 examples with temperature 0.5: Average Cosine Similarity = 0.8113872706890106, Average ROUGE Scores = {'rouge1': 0.48163576039478545, 'rouge2': 0.23428479418275056, 'rougeL': 0.317383182677783}\n",
      "Tested 1 examples with temperature 0.7: Average Cosine Similarity = 0.8145684063434601, Average ROUGE Scores = {'rouge1': 0.4660504852355472, 'rouge2': 0.21347260353029268, 'rougeL': 0.30695809446267674}\n",
      "Tested 2 examples with temperature 0.3: Average Cosine Similarity = 0.8260851621627807, Average ROUGE Scores = {'rouge1': 0.5064617248631298, 'rouge2': 0.26104423173957536, 'rougeL': 0.3441954067356462}\n",
      "Tested 2 examples with temperature 0.5: Average Cosine Similarity = 0.8329042851924896, Average ROUGE Scores = {'rouge1': 0.5088764204084966, 'rouge2': 0.26502297368212363, 'rougeL': 0.3450406367526724}\n",
      "Tested 2 examples with temperature 0.7: Average Cosine Similarity = 0.8198516875505447, Average ROUGE Scores = {'rouge1': 0.5048189772901274, 'rouge2': 0.2804621685757076, 'rougeL': 0.3782842808760422}\n",
      "Tested 3 examples with temperature 0.3: Average Cosine Similarity = 0.8542855113744736, Average ROUGE Scores = {'rouge1': 0.5757694078859568, 'rouge2': 0.3590121762465269, 'rougeL': 0.41000797872465167}\n",
      "Tested 3 examples with temperature 0.5: Average Cosine Similarity = 0.8341294944286346, Average ROUGE Scores = {'rouge1': 0.5274027092115156, 'rouge2': 0.3053748575290694, 'rougeL': 0.3791014517262685}\n",
      "Tested 3 examples with temperature 0.7: Average Cosine Similarity = 0.8152674555778503, Average ROUGE Scores = {'rouge1': 0.5184913197351951, 'rouge2': 0.2865785188564752, 'rougeL': 0.38012084042183325}\n",
      "Best parameters are (3, 0.3, {'rouge1': 0.5757694078859568, 'rouge2': 0.3590121762465269, 'rougeL': 0.41000797872465167}) with a cosine score of 0.8542855113744736\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "api_key = os.getenv('OPENAI_API_KEY', 'sk-key-here')  # Replace with your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Load the sentence embedding model for similarity calculation\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Function to construct prompt with N examples\n",
    "def construct_prompt(examples, current_text):\n",
    "    prompt = \"Summarize this Albanian text based on the following examples:\\n\"\n",
    "    for idx, example in examples.iterrows():\n",
    "        prompt += f\"Text: {example['text']} Summary: {example['summarization']}\\n\"\n",
    "    prompt += f\"Text: {current_text} Summary:\"\n",
    "    return prompt\n",
    "\n",
    "# Function to call the model\n",
    "def generate_summary(prompt, temperature):\n",
    "    try:\n",
    "        completion = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",  # Adjust model as necessary\n",
    "            prompt=prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return completion.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to evaluate summaries\n",
    "def calculate_cosine_similarity(reference, summary):\n",
    "    ref_embedding = embedding_model.encode(reference, convert_to_tensor=True)\n",
    "    summary_embedding = embedding_model.encode(summary, convert_to_tensor=True)\n",
    "    cosine_score = util.pytorch_cos_sim(ref_embedding, summary_embedding).item()\n",
    "    return cosine_score\n",
    "\n",
    "# Iterate over combinations of number of examples and temperature\n",
    "example_counts = [1, 2, 3]  # Number of examples to try\n",
    "temperatures = [0.3, 0.5, 0.7]  # Different temperatures to try\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for count, temp in itertools.product(example_counts, temperatures):\n",
    "    examples = data.sample(n=count)\n",
    "    scores = []\n",
    "    rouge_scores = []\n",
    "\n",
    "    for _, current_example in data.iterrows():\n",
    "        prompt = construct_prompt(examples, current_example['text'])\n",
    "        generated_summary = generate_summary(prompt, temp)\n",
    "        score = calculate_cosine_similarity(current_example['summarization'], generated_summary)\n",
    "        scores.append(score)\n",
    "        # Calculate ROUGE scores\n",
    "        rouge_result = scorer.score(current_example['summarization'], generated_summary)\n",
    "        rouge_scores.append(rouge_result)\n",
    "    \n",
    "    average_score = sum(scores) / len(scores)\n",
    "    average_rouge = {key: sum(score[key].fmeasure for score in rouge_scores) / len(rouge_scores) for key in rouge_scores[0]}\n",
    "    \n",
    "    if average_score > best_score:\n",
    "        best_score = average_score\n",
    "        best_params = (count, temp, average_rouge)\n",
    "        \n",
    "    print(f\"Tested {count} examples with temperature {temp}: Average Cosine Similarity = {average_score}, Average ROUGE Scores = {average_rouge}\")\n",
    "\n",
    "print(f\"Best parameters are {best_params} with a cosine score of {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d081e-f900-4a9d-915e-fb6695aaea57",
   "metadata": {},
   "source": [
    "## Conclusion and Comparative Analysis\n",
    "\n",
    "After applying different strategies for summarizing Albanian parliamentary speeches, we have gathered significant insights into the effectiveness of multishot prompt engineering compared to the traditional approach of fine-tuning a language model.\n",
    "\n",
    "### Multishot Prompt Engineering Performance\n",
    "- **Test Setup**: Employed 3 examples with a temperature setting of 0.3.\n",
    "- **Performance Metrics**:\n",
    "  - **Average Cosine Similarity**: 0.8543, indicating a high degree of semantic similarity between the generated summaries and the reference texts.\n",
    "  - **ROUGE Scores**:\n",
    "    - ROUGE-1: 0.5758\n",
    "    - ROUGE-2: 0.3590\n",
    "    - ROUGE-L: 0.4100\n",
    "  These scores reflect good overlap with the reference summaries, especially considering the complexity of the summarization task.\n",
    "\n",
    "### Fine-Tuning Model Performance\n",
    "- **Performance Metrics**:\n",
    "  - **Average Cosine Similarity**: 0.4731, which is significantly lower compared to the multishot approach.\n",
    "  - **ROUGE Scores**:\n",
    "    - ROUGE-1: 0.4769\n",
    "    - ROUGE-2: 0.2626\n",
    "    - ROUGE-L: 0.4460\n",
    "  While the fine-tuned model shows competent summarization capabilities, it falls short of the multishot approach in terms of semantic similarity.\n",
    "\n",
    "### Final Assessment\n",
    "The comparison clearly indicates that **multishot prompt engineering not only outperforms the fine-tuned model in terms of similarity measures but also maintains competitive ROUGE scores**. This suggests that multishot prompting, despite being a less resource-intensive method, can be an effective strategy for tasks like summarizing legislative proceedings, offering a promising alternative to the more costly and computationally demanding fine-tuning process.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
